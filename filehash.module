<?php

/**
 * @file
 * Generate hashes for each uploaded file.
 */

use Drupal\Core\Entity\EntityInterface;
use Drupal\file\FileInterface;

/**
 * Returns array of enabled hash algorithms.
 */
function filehash_algos() {
  return array_diff(\Drupal::config('filehash.settings')->get('algos'), array(0));
}

/**
 * Implements hook_ENTITY_TYPE_create().
 */
function filehash_file_create(EntityInterface $file) {
  $file->filehash = array_fill_keys(array('md5', 'sha1', 'sha256'), NULL);
  foreach (filehash_algos() as $algo) {
    $file->filehash[$algo] = hash_file($algo, $file->getFileUri());
  }
}

/**
 * Implements hook_ENTITY_TYPE_delete().
 */
function filehash_file_delete(EntityInterface $file) {
  db_delete('filehash')
    ->condition('fid', $file->id())
    ->execute();
}

/**
 * Implements hook_ENTITY_TYPE_insert().
 */
function filehash_file_insert(EntityInterface $file) {
  filehash_save($file);
}

/**
 * Implements hook_ENTITY_TYPE_load().
 */
function filehash_file_load($files) {
  $algos = filehash_algos();
  if ($algos) {
    $result = db_select('filehash')
      ->fields('filehash')
      ->condition('fid', array_keys($files), 'IN')
      ->execute();
    foreach ($result as $record) {
      foreach ($algos as $algo) {
        $files[$record->fid]->filehash[$algo] = $record->$algo;
      }
    }
    // Generate hash if it does not already exist for the file.
    foreach ($files as $fid => $file) {
      foreach ($algos as $algo) {
        if (empty($file->filehash[$algo])) {
          filehash_save($files[$fid]);
          break;
        }
      }
    }
  }
}

/**
 * Implements hook_ENTITY_TYPE_update().
 */
function filehash_file_update(EntityInterface $file) {
  filehash_save($file);
}

/**
 * Implements hook_file_validate().
 */
function filehash_file_validate(FileInterface $file) {
  $errors = array();
  if (\Drupal::config('filehash.settings')->get('dedupe')) {
    foreach (filehash_algos() as $algo) {
      if (db_query("SELECT COUNT(*) FROM {filehash} WHERE $algo = :hash", array(':hash' => $file->filehash[$algo]))->fetchField()) {
        $errors[] = t('Sorry, duplicate files are not permitted.');
        break;
      }
    }
  }
  return $errors;
}

/**
 * Returns array of human-readable hash algorithm names.
 */
function filehash_names() {
  return array('md5' => 'MD5', 'sha1' => 'SHA-1', 'sha256' => 'SHA-256');
}

/**
 * Implements hook_ENTITY_TYPE_build_defaults_alter().
 */
function filehash_node_build_defaults_alter(array &$build, EntityInterface $node, $view_mode, $langcode) {
  if ($view_mode == 'rss') {
    // The <media:hash> element only supports MD5 and SHA-1.
    $algos = filehash_algos();
    if (!isset($algos['md5']) && !isset($algos['sha1'])) {
      return;
    }
    // The following field types are currently supported.
    $fields = entity_load_multiple_by_properties('field_config', array('entity_type' => 'node', 'bundle' => $node->getType(), 'field_type' => 'file'));
    $fields += entity_load_multiple_by_properties('field_config', array('entity_type' => 'node', 'bundle' => $node->getType(), 'field_type' => 'image'));
    foreach ($fields as $field) {
      foreach ($node->{$field->getName()} as $item) {
        if ($item->isDisplayed()) {
          // Add <media:hash> elements for at most one file per RSS item.
          $file = file_load($item->target_id);
          filehash_rss_elements($file, $node);
          return;
        }
      }
    }
  }
}

/**
 * Adds <media:hash> RSS elements to $node object.
 */
function filehash_rss_elements($file, $node) {
  $names = array('md5' => 'md5', 'sha1' => 'sha-1');
  foreach ($names as $algo => $name) {
    if (!empty($file->filehash[$algo])) {
      $node->rss_elements[] = array(
        'key' => 'media:hash',
        'attributes' => array('algo' => $name),
        'value' => $file->filehash[$algo],
      );
    }
  }
  $node->rss_namespaces['xmlns:media'] = 'http://search.yahoo.com/mrss/';
}

/**
 * Calculates and saves the file hashes.
 */
function filehash_save(FileInterface $file) {
  foreach (filehash_algos() as $algo) {
    // Regenerate the hash as the file may have been modified.
    $file->filehash[$algo] = hash_file($algo, $file->getFileUri());
  }
  db_merge('filehash')
    ->key(array('fid' => $file->id()))
    ->fields($file->filehash)
    ->execute();
}
