<?php

/**
 * @file
 * Generate hashes for each uploaded file.
 */

use Drupal\Core\Database\DatabaseExceptionWrapper;
use Drupal\Core\Entity\EntityFormInterface;
use Drupal\Core\Entity\EntityInterface;
use Drupal\Core\Entity\EntityTypeInterface;
use Drupal\Core\Field\BaseFieldDefinition;
use Drupal\Core\Form\FormStateInterface;
use Drupal\Core\Link;
use Drupal\Core\Routing\RouteMatchInterface;
use Drupal\Core\Url;
use Drupal\field\FieldConfigInterface;
use Drupal\file\Entity\File;
use Drupal\file\FileInterface;
use Drupal\file\Plugin\Field\FieldType\FileFieldItemList;
use Drupal\filehash\FileHashInterface;

/**
 * Implements hook_entity_base_field_info().
 */
function filehash_entity_base_field_info(EntityTypeInterface $entity_type) {
  $fields = [];
  if ('file' === $entity_type->id()) {
    $columns = Drupal::service('filehash')->columns();
    $labels = Drupal::service('filehash')->labels();
    $lengths = Drupal::service('filehash')->lengths();
    $descriptions = Drupal::service('filehash')->descriptions();
    $original = Drupal::config('filehash.settings')->get('original');
    if ($original) {
      $original_labels = Drupal::service('filehash')->originalLabels();
      $original_descriptions = Drupal::service('filehash')->originalDescriptions();
    }
    foreach ($columns as $column) {
      $fields[$column] = BaseFieldDefinition::create('filehash')
        ->setLabel($labels[$column])
        ->setSetting('max_length', $lengths[$column])
        ->setDescription($descriptions[$column]);
      if ($original) {
        $fields["original_$column"] = BaseFieldDefinition::create('filehash')
          ->setLabel($original_labels[$column])
          ->setSetting('max_length', $lengths[$column])
          ->setDescription($original_descriptions[$column]);
      }
    }
  }
  return $fields;
}

/**
 * Implements hook_entity_storage_load().
 *
 * Generates hash if it does not already exist for the file.
 */
function filehash_entity_storage_load($files, $entity_type) {
  if ('file' !== $entity_type) {
    return;
  }
  // @todo Add a setting to toggle the auto-hash behavior?
  foreach ($files as $file) {
    foreach (Drupal::service('filehash')->columns() as $column) {
      if (!$file->{$column}->value) {
        $file->original = clone($file);
        // Entity post-save will clean up the dangling "original" property.
        $file->save();
        break;
      }
    }
  }
}

/**
 * Implements hook_field_widget_single_element_WIDGET_TYPE_form_alter().
 */
function filehash_field_widget_single_element_managed_file_form_alter(&$element, FormStateInterface $form_state, $context) {
  $settings = $context['items']->getFieldDefinition()->getThirdPartySettings('filehash');
  if (!empty($settings['dedupe'])) {
    $strict = FileHashInterface::STRICT_DEDUPE == $settings['dedupe'];
    $element['#upload_validators']['filehash_validate_dedupe'] = [$strict];
  }
}

/**
 * Implements hook_ENTITY_TYPE_create().
 */
function filehash_file_create(EntityInterface $file) {
  Drupal::service('filehash')->hash($file, NULL, Drupal::config('filehash.settings')->get('original'));
}

/**
 * Implements hook_ENTITY_TYPE_presave().
 */
function filehash_file_presave(EntityInterface $file) {
  if (Drupal::config('filehash.settings')->get('rehash')) {
    // Regenerate all hashes.
    Drupal::service('filehash')->hash($file);
  }
  else {
    // Only generate missing hashes.
    foreach (Drupal::service('filehash')->columns() as $column) {
      if (empty($file->{$column}->value)) {
        Drupal::service('filehash')->hash($file, $column);
      }
    }
  }
}

/**
 * Implements hook_file_validate().
 */
function filehash_file_validate(FileInterface $file) {
  $dedupe = Drupal::config('filehash.settings')->get('dedupe');
  $strict = FileHashInterface::STRICT_DEDUPE == $dedupe;
  return $dedupe ? filehash_validate_dedupe($file, $strict) : [];
}

/**
 * Implements hook_form_FORM_ID_alter().
 */
function filehash_form_field_config_edit_form_alter(array &$form, FormStateInterface $form_state) {
  if (!($form_state->getFormObject() instanceof EntityFormInterface)) {
    return;
  }
  $field = $form_state->getFormObject()->getEntity();
  if (!($field instanceof FieldConfigInterface)) {
    return;
  }
  if (!is_a($field->getClass(), FileFieldItemList::class, TRUE)) {
    return;
  }
  $settings = $field->getThirdPartySettings('filehash');
  $form['settings']['filehash'] = [
    '#type'    => 'container',
    '#tree'    => TRUE,
    '#parents' => ['third_party_settings', 'filehash'],
  ];
  $form['settings']['filehash']['dedupe'] = [
    '#type'          => 'select',
    '#title'         => t('Disallow duplicate files'),
    '#options'       => [t('Off'), t('Enabled'), t('Strict')],
    '#default_value' => $settings['dedupe'] ?? 0,
    '#description'   => t('If enabled, prevent duplicate uploaded files from being saved when the file already exists as a permanent file. If strict, also include temporary files in the duplicate check, which prevents duplicates from being uploaded at the same time. Note, enabling this setting has privacy implications, as it allows users to determine if a particular file has been uploaded to the site.'),
  ];
}

/**
 * Implements hook_help().
 */
function filehash_help($route_name, RouteMatchInterface $route_match) {
  switch ($route_name) {
    case 'help.page.filehash':
    case 'filehash.admin':
      $output = array_fill(0, 2, ['#type' => 'html_tag', '#tag' => 'p']);
      $output[0]['#value'] = t('File Hash module generates and stores hashes for each file uploaded to the site. Hashes allow files to be uniquely identified, duplicate files to be detected, and copies to be verified against the original source.');
      $output[1]['#value'] = function_exists('sodium_crypto_generichash_init') ? t('Note, the BLAKE2b hash algorithm requires the Sodium PHP extension, which is currently enabled.') : t('Note, the BLAKE2b hash algorithm requires the Sodium PHP extension, which is not currently enabled.');
      return $output;
  }
}

/**
 * Checks that file is not a duplicate.
 */
function filehash_validate_dedupe(FileInterface $file, $strict = FALSE) {
  $errors = [];
  // We only run the dedupe check on initial file creation.
  if (!$file->id()) {
    foreach (Drupal::service('filehash')->columns() as $column) {
      try {
        $fid = Drupal::service('filehash')->duplicateLookup($column, $file, $strict);
      }
      catch (DatabaseExceptionWrapper $e) {
        Drupal::service('filehash')->addColumns();
        $fid = Drupal::service('filehash')->duplicateLookup($column, $file, $strict);
      }
      if ($fid) {
        $error = t('Sorry, duplicate files are not permitted.');
        if (Drupal::currentUser()->hasPermission('access files overview')) {
          try {
            $url = Url::fromRoute('view.files.page_2', ['arg_0' => $fid], ['attributes' => ['target' => '_blank']]);
            $error = t('This file has already been uploaded as %filename.', [
              '%filename' => Link::fromTextAndUrl(File::load($fid)->label(), $url)->toString(),
            ]);
          }
          catch (Exception $e) {
            // Maybe the view was disabled?
          }
        }
        $errors[] = $error;
        break;
      }
    }
  }
  return $errors;
}
